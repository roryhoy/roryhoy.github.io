<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="shortcut icon" type="image/icon" href="../images/hoyfavicon.ico" />

	<link rel="canonical" href="https://www.rhoy.ca/projects/soundpainting_recognition.html" />
	<meta name="description"
		content="ESP Soundpainting Gesture Recognition is a gesture recognition performance tool by Rory Hoy and Doug Van Nort.">
	<meta name="keywords"
		content="soundpainting, gesture, recognition, mediapipe, Projects, Rory, Hoy, PhD, student, sound, artist, Canadian, York, University, artificial, life, telematic, music, telepresence, virtual, digital, media, dispersion, Toronto">
	<meta name="author" content="Rory Hoy">
	<meta name="robots" content="index, follow">
	<meta name="twitter:title" content="Rory Hoy · ESP Soundpainting Gesture Recognition" />
	<meta name="twitter:image" content="/images/soundpainting/density-gesture.png" />
	<meta name="twitter:url" content="https://www.rhoy.ca/projects/soundpainting_recognition.html" />
	<meta name="twitter:card" content="summary" />
	<meta name="twitter:description"
		content="ESP Soundpainting Gesture Recognition is a gesture recognition performance tool by Rory Hoy and Doug Van Nort." />
	<meta itemprop="name" content="Rory Hoy · ESP Soundpainting Gesture Recognition" />
	<meta itemprop="url" content="https://www.rhoy.ca/projects/soundpainting_recognition.html" />
	<meta itemprop="description"
		content="ESP Soundpainting Gesture Recognition is a gesture recognition performance tool by Rory Hoy and Doug Van Nort." />
	<meta itemprop="thumbnailUrl" content="/images/soundpainting/density-gesture.png" />
	<meta property="og:site_name" content="Rory Hoy" />
	<meta property="og:title" content="Rory Hoy · ESP Soundpainting Gesture Recognition" />
	<meta property="og:url" content="https://www.rhoy.ca/projects/soundpainting_recognition.html" />
	<meta property="og:type" content="website" />
	<meta property="og:description"
		content="ESP Soundpainting Gesture Recognition is a gesture recognition performance tool by Rory Hoy and Doug Van Nort." />
	<meta property="og:image" content="/images/soundpainting/density-gesture.png" />
	<meta property="og:image:width" content="1890" />
	<meta property="og:image:height" content="831" />

	<!--Bootstrap CSS-->
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css" rel="stylesheet"
		integrity="sha384-KyZXEAg3QhqLMpG8r+8fhAXLRk2vvoC2f3B09zVXn8CA5QIVfZOJ3BCsw2P0p/We" crossorigin="anonymous">
	<link rel="stylesheet" href="../site.css">

	<!--Bootstrap + Popper JS-->
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/js/bootstrap.bundle.min.js"
		integrity="sha384-U1DAWAznBHeqEIlVSCgzq+c9gqGAJn5c/t99JyeKa9xxaYpSvHU5awsuZVVFIhvj"
		crossorigin="anonymous"></script>
	<title>Rory Hoy · eLabOrateD</title>

</head>

<body>
	<div id="site-header"></div>
	<main class="w-100">
		<div class="body-div mx-auto">
			<div class="container">
				<div class="project-title">
					<h2>ESP Soundpainting Gesture Recognition</h2>
					<div class="project-date">&ensp;·&ensp;2025</div>
				</div>
				<div class="row py-lg-1 py-sm-0">
					<div class="col-lg-6 col-sm-12 px-1 proj">
						<p>This project presents a machine-learning system for automatic recognition of Soundpainting
							gestures, enabling direct, real-time control of computational musical agents by a conductor.
							Built in Python and using MediaPipe hand and skeletal tracking, the system recognizes 41
							electro/acoustic Soundpainting (ESP) gestures from a standard webcam, without requiring
							specialized hardware.</p>

						<p>Gestures are decomposed into single-hand “gesture components” and classified across four
							vertical body regions (legs, torso, head, above head) using multiple trained models. These
							components are recombined into full Soundpainting gestures, allowing flexible, modular
							expansion
							of the gesture vocabulary and composer-specific training. Recognition output is transmitted
							via
							OSC to Max, where it controls autonomous musical agents designed as stylistic
							“doppelgangers” of
							human performers in <a
								href="https://dvntsea.com/projects/thee-doug-van-nort-electro-acoustic-orchestra-2020-present/"
								target="_blank">thee Doug Van Nort Electro-Acoustic
								Orchestra</a>. These agents were created for the <a
								href="/projects/ensemble_co-create.html" target="_blank">Human/Machine Ensemble
								Performance</a>
							project.</p>

						<p>The system removes the need for a human intermediary between conductor and machine
							performers,
							supports composer-agnostic retraining, and achieves an average recognition accuracy of ~82%
							across tested gestures.</p>

						<p>Published in the Sound and Music Computing 2025 conference proceedings:
							<a href="https://zenodo.org/records/15843324" target="_blank">[PDF available on Zenodo]</a>
						</p>
						<p>ESP Soundpainting Gesture Recognition was preseted at SMC 2025 in Graz, Austria. <br>
							You can watch the presentation <a href="https://vimeo.com/1100238572/43bd884032#t=49m00s"
								target="_blank">here</a>!</p>
					</div>

					<div class="col-lg-6 col-sm-12 px-1 proj">
						<div class="col-lg-6 col-sm-12 px-1 py-1 proj">
							<iframe width="560" height="315"
								src="https://www.youtube.com/embed/T0DCT_MxK_8?si=H6grYi0lg40RGB8H"
								title="YouTube video player" frameborder="0"
								allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
								referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
						</div>
						<p> Above: A set of example gestures, performed with estimation logging displayed. "EAO
							Gesture" refers to the resulting classified and output gesture. The bottom interfaces
							depicts the Max routing patch for incoming messages, and all input can be seen on the
							right-side print console.</p>
						<p>Below: System configuration settings on startup.</p>
						<img src="/images/soundpainting/setup_ui.png"
							class="img-fluid rounded proj-page-thumb"
							alt="ESP Soundpainting Gesture Recognition Accuracy Chart">
					</div>

				</div>
				<div class="row py-lg-1 py-sm-0">
					<div class="col-lg-6 col-sm-12 px-1 py-1 proj">
						<img src="/images/soundpainting/test_accuracy_long.png"
							class="img-fluid rounded proj-page-thumb"
							alt="ESP Soundpainting Gesture Recognition Accuracy Chart">
					</div>
					<div class="col-lg-6 col-sm-12 px-1 py-1 proj">
						<p>The system achieves an overall average gesture recognition accuracy of 78.3%, increasing to
							81.9%
							when excluding gestures found to be unreliable in practice. Of the 41 implemented ESP
							gestures,
							32 achieve ≥75% accuracy, with nine gestures reaching 100% accuracy across both tested
							conductors. These highest-performing gestures are predominantly static, clearly defined hand
							shapes with minimal temporal variation.</p>
						<p>Accuracy was evaluated using cross-performer testing to assess interoperability. Models
							trained
							by one conductor were tested by another, with gestures performed under natural performance
							timing rather than exaggerated or slowed movements. A gesture was counted as correct only if
							it
							was recognized on the first attempt, within a 1–2 second window that matches human
							perceptual
							and response times in live Soundpainting performance.
						</p>
					</div>
				</div>


			</div>
		</div>
	</main>
</body>
<script>
	fetch("/header.html")
		.then(r => r.text())
		.then(html => {
			document.getElementById("site-header").innerHTML = html;
			document.querySelector('a[href="/projects.html"]')?.classList.add("active");
			requestAnimationFrame(() => {
				document.body.classList.add("reveal");
			});
		});
</script>

</html>